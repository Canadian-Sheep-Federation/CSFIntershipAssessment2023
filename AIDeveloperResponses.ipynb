{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Jupyter Notebook to Processing Pipeline\n",
    "\n",
    "**Question**:\n",
    "Given a jupyter notebook that has a functioning implementation of a machine learning model that identifies unique individuals out of a crowd through gait analysis, how would you translate that notebook to a piece of software that can be used to apply the model to any arbitrary images or videos provided.\n",
    "\n",
    "**Answer**: \n",
    "Given that the notebook already has a working model, I will need to save that model as a file, which would allow me to reload it whenever I want to run a image or video through it. Therefore, I would take the following steps: \n",
    "1. First, within the notebook I would add an import to the joblib library.\n",
    "2. To save the model, I call joblib.dump(model, *file_location*), which will save the model's parameters and functions into a file with a designated location.\n",
    "3. Now, I can call joblib.load(*file_location*) wherever the model is needed to load the model back and use it to process images and videos that I pass to the backend.\n",
    "\n",
    "There are many ways to save the model, not just using joblib. If using the PyTorch or Tensorflow libraries, they both have save() functions to save a model as a file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Demo\n",
    "\n",
    "**Question**: \n",
    "Write a toy implementation of whatever machine learning concept you would like in order to demonstrate your skills. This doesn't need to be in the notebook if you want to use something other than python.\n",
    "\n",
    "**Answer**:\n",
    "Below, I have created a neural network with 2 hidden layers that is trained on the MNIST dataset to recognize numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import reshape, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and transform data\n",
    "(train_data, train_target), (valid_data, valid_target) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = reshape(tf.keras.utils.normalize(train_data, 1), [train_data.shape[0], -1])\n",
    "valid_data = reshape(tf.keras.utils.normalize(valid_data, 1), [valid_data.shape[0], -1])\n",
    "\n",
    "train_target = one_hot(train_target, 10)\n",
    "valid_target = one_hot(valid_target, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(256, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "#assemble\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2315 - accuracy: 0.9315\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0911 - accuracy: 0.9723\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0606 - accuracy: 0.9808\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0433 - accuracy: 0.9856\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0318 - accuracy: 0.9894\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0254 - accuracy: 0.9918\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0213 - accuracy: 0.9926\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0158 - accuracy: 0.9948\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0157 - accuracy: 0.9944\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0132 - accuracy: 0.9955\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1048 - accuracy: 0.9774\n"
     ]
    }
   ],
   "source": [
    "# train model and evaluate training and testing accuracies\n",
    "model.fit(train_data, train_target, epochs = 10)\n",
    "valid_accuracy = model.evaluate(valid_data, valid_target)[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model above can predict the value from images of numbers between 0-9 with a training accuracy of **~99%**, validation accuracy of **~97.5%**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
